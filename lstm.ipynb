{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8defb8d3a576fa42",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.data import preprocess_data, embed_data"
   ],
   "id": "54727e7ce4ab82df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Data Preprocessing",
   "id": "d82c67698eea93cd"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_train, df_eval = preprocess_data()\n",
    "df_train, df_eval = embed_data(df_train, df_eval)\n",
    "\n",
    "X = df_train.drop(columns=['EventType', 'MatchID', 'PeriodID', 'ID']).values\n",
    "y = df_train['EventType'].values\n",
    "\n",
    "X_id = df_eval['ID'].values\n",
    "X_eval = df_eval.drop(columns=['MatchID', 'PeriodID', 'ID']).values"
   ],
   "id": "eeb01d36c0d7c519"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Model Training",
   "id": "4fc7abf300b9b7d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# For Kaggle submission save\n",
    "def save_predictions_model(clf, params, accuracy):\n",
    "    clf.fit(X, y)\n",
    "    preds = clf.predict(X_eval)\n",
    "    pred_df = pd.DataFrame({'ID': X_id, 'EventType': preds})\n",
    "    # <clf name>/<params>/<filename>_predictions.csv\n",
    "    params = params.replace(' ', '')\n",
    "    today = datetime.today().strftime('%Y%m%d')\n",
    "    file_folder = f\"pred-{today}/{clf.__class__.__name__}-{accuracy}/{params}/\"\n",
    "    os.makedirs(file_folder, exist_ok=True)\n",
    "    file_path = os.path.join(file_folder, f\"{clf.__class__.__name__}_predictions.csv\")\n",
    "    pred_df.to_csv(file_path, index=False)\n",
    "    print(f\"Predictions saved to {file_path}\")\n",
    "    return file_folder\n"
   ],
   "id": "619bdd5576ac127"
  },
  {
   "cell_type": "markdown",
   "id": "ba7ed1d3-3797-4c08-9d94-c79debb4baec",
   "metadata": {},
   "source": "## LSTM"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffd1a21a-2918-4930-a9b5-7d904bc86d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, labels, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        label = labels[i+seq_length]\n",
    "        sequences.append(seq)\n",
    "        targets.append(label)\n",
    "    return torch.tensor(sequences, dtype=torch.float32), torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "seq_length = 50  # Choose time step length\n",
    "X_train, y_train = create_sequences(X, y, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e1b783c-060e-43c7-b22c-79f78d5d338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_421313/1436043462.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
      "/tmp/ipykernel_421313/1436043462.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
      "/tmp/ipykernel_421313/1436043462.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_valid, dtype=torch.float32)\n",
      "/tmp/ipykernel_421313/1436043462.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_valid, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "input_size = X_train.shape[-1]  # numberOfInputFeatures\n",
    "# print(input_size)\n",
    "hidden_size = 80  # hidden layer size\n",
    "num_layers = 1  # Number of LSTM layers\n",
    "num_classes = 2  # Number of categories\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1000  # Number of iterations\n",
    "batch_size = 16\n",
    "stop_threshold = 0.001  # Threshold to stop training\n",
    "\n",
    "# Convert data to Tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9322532-7c15-4f2f-a8ad-c8f675eac4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "        \n",
    "LSTM_model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(LSTM_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8bd64-12a5-4040-b64b-0987fceb5ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ed2730f24649b9ae36de797673aba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training model\n",
    "LSTM_model.train()\n",
    "progress_bar = tqdm(range(num_epochs), desc=\"Training\")  # Create a progress bar\n",
    "for epoch in progress_bar:\n",
    "    epoch_loss = 0.0\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(dataloader):\n",
    "        # X_batch = X_batch.view(X_batch.size(0), 1, -1)  # Add time step dimension\n",
    "        X_batch, y_batch = X_batch.to(LSTM_model.fc.weight.device), y_batch.to(LSTM_model.fc.weight.device)\n",
    "        # forward propagation\n",
    "        outputs = LSTM_model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    progress_bar.set_postfix({'Loss': avg_loss})\n",
    "    \n",
    "    # Determine whether the stopping condition is met\n",
    "    if avg_loss < stop_threshold:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}, Loss: {avg_loss:.4f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e725ecc-2c1b-48dc-a496-10662b003ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.16%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # X_test = X_test.view(X_test.size(0), 1, -1)\n",
    "        X_test, y_test = X_test.to(model.fc.weight.device), y_test.to(model.fc.weight.device)\n",
    "        outputs = model(X_test)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "test_model(LSTM_model, X_train_tensor, y_train_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
